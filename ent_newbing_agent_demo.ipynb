{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8acaa4-7ded-4da3-935d-dd71ba029a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pypdf\n",
    "#!pip install langchain\n",
    "#!pip install gradio\n",
    "#!pip install docx2txt\n",
    "#!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48179687-b1d3-4073-bbd5-f99c1947e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "  Using profile: default\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a coroutine was expected, got ' 香格里拉位于中国西藏自治区东南部,是传说中的极乐世界。主要有以下几点关于香格里拉的地理位置:\\n\\n1. 香格里拉位于横断山脉的怒江河谷地带,海拔约3300米,周围被高山环抱。\\n\\n2. 它属于迪庆藏族自治州管辖,地处云南省西北部。距离丽江市约430公里,离省会昆明市约680公里。\\n\\n3. 香格里拉县城位于金沙江和白马雪山之间,拥有美丽的自然风光和藏族传统文化。\\n\\n4. 香格里拉是著名的旅游胜地,有“东方小瑞士”之称。主要景点有松赞林寺、白水台等。\\n\\n5. 1999年,中国政府在这里建立了香格里拉市,并办起了香格里拉亚洲论坛。\\n\\n6. 香格里拉在藏语中的意思是“心中的日月”。它来源于英国作家詹姆斯·希尔顿的小说《消失的地平线》,代表理想家园。'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m###test the bedrock langchain integration###\u001b[39;00m\n\u001b[1;32m    131\u001b[0m coro \u001b[38;5;241m=\u001b[39m bedrock_llm\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m香格里拉在哪里?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m callback\u001b[38;5;241m.\u001b[39maiter():\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/asyncio/tasks.py:337\u001b[0m, in \u001b[0;36mcreate_task\u001b[0;34m(coro, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Schedule the execution of a coroutine object in a spawn task.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mReturn a Task object.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[0;32m--> 337\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m _set_task_name(task, name)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m task\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py:438\u001b[0m, in \u001b[0;36mBaseEventLoop.create_task\u001b[0;34m(self, coro, name)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39m_source_traceback:\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m task\u001b[38;5;241m.\u001b[39m_source_traceback[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: a coroutine was expected, got ' 香格里拉位于中国西藏自治区东南部,是传说中的极乐世界。主要有以下几点关于香格里拉的地理位置:\\n\\n1. 香格里拉位于横断山脉的怒江河谷地带,海拔约3300米,周围被高山环抱。\\n\\n2. 它属于迪庆藏族自治州管辖,地处云南省西北部。距离丽江市约430公里,离省会昆明市约680公里。\\n\\n3. 香格里拉县城位于金沙江和白马雪山之间,拥有美丽的自然风光和藏族传统文化。\\n\\n4. 香格里拉是著名的旅游胜地,有“东方小瑞士”之称。主要景点有松赞林寺、白水台等。\\n\\n5. 1999年,中国政府在这里建立了香格里拉市,并办起了香格里拉亚洲论坛。\\n\\n6. 香格里拉在藏语中的意思是“心中的日月”。它来源于英国作家詹姆斯·希尔顿的小说《消失的地平线》,代表理想家园。'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import boto3\n",
    "import asyncio\n",
    "from botocore.config import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.agents import Tool, AgentExecutor, AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "from langchain.callbacks.streaming_stdout_final_only import (\n",
    "    FinalStreamingStdOutCallbackHandler,\n",
    ")\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks import AsyncIteratorCallbackHandler\n",
    "from typing import Dict\n",
    "from typing import Any, Dict, List, Optional,Union\n",
    "\n",
    "\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    runtime: Optional[bool] = True,\n",
    "):\n",
    "  \n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "        \n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    client_kwargs[\"aws_access_key_id\"] = os.environ.get(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "    client_kwargs[\"aws_secret_access_key\"] = os.environ.get(\"AWS_SECRET_ACCESS_KEY\",\"\")\n",
    "    \n",
    "    bedrock_client = session.client(\n",
    "        service_name=service_name,\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client\n",
    "\n",
    "\n",
    "\n",
    "## for aksk bedrock\n",
    "def get_bedrock_aksk(secret_name='chatbot_bedrock', region_name = \"us-west-2\"):\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = json.loads(get_secret_value_response['SecretString'])\n",
    "    return secret['BEDROCK_ACCESS_KEY'],secret['BEDROCK_SECRET_KEY']\n",
    "\n",
    "ACCESS_KEY, SECRET_KEY=get_bedrock_aksk()\n",
    "\n",
    "#role based initial client#######\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"  # E.g. \"us-east-1\"\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "#os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\"  # E.g. \"arn:aws:...\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=ACCESS_KEY\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=SECRET_KEY\n",
    "\n",
    "\n",
    "#新boto3 sdk只能session方式初始化bedrock\n",
    "boto3_bedrock = get_bedrock_client(\n",
    "    #assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "parameters_bedrock = {\n",
    "    \"max_tokens_to_sample\": 2048,\n",
    "    #\"temperature\": 0.5,\n",
    "    \"temperature\": 0,\n",
    "    #\"top_k\": 250,\n",
    "    #\"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock,model_kwargs=parameters_bedrock)\n",
    "#####langchain bedrock 不支持异步apredict，无法流式输出##########\n",
    "#callback = AsyncIteratorCallbackHandler()\n",
    "#bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, streaming=True,callbacks=[callback],model_kwargs=parameters_bedrock)\n",
    "#coro = bedrock_llm.apredict(\"香格里拉在哪里?\\n\")\n",
    "#asyncio.create_task(coro)\n",
    "#async for token in callback.aiter():\n",
    "#    print(token)\n",
    "\n",
    "\n",
    "class BedrockModelWrapper(Bedrock):\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        prompt = \"\\nHuman: \\n\" + prompt + \"\\nAssistant:\"   ## Satisfy Bedrock-Claude prompt requirements\n",
    "        return super()._call(prompt, stop, run_manager, **kwargs)\n",
    "\n",
    "\n",
    "bedrock_llm_additional = BedrockModelWrapper(model_id=\"anthropic.claude-v2\", \n",
    "                                          client=boto3_bedrock, \n",
    "                                          model_kwargs=parameters_bedrock)\n",
    "\n",
    "\n",
    "##use customerized outputparse to fix claude not match \n",
    "##langchain's openai ReAct template don't have \n",
    "##final answer issue \n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        #print(\"cur step's llm_output ===\"+llm_output)\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output},\n",
    "                log=llm_output,\n",
    "            )\n",
    "            #raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a38bfce2-6f96-46c8-94df-048d9b27069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FullContentRetriever(BaseRetriever):\n",
    "    doc_path={}\n",
    "    def _get_content_type(self,doc_path:str):\n",
    "        fullname=\"\"\n",
    "        for root, dirs, files in os.walk(doc_path):\n",
    "            for f in files:\n",
    "                fullname = os.path.join(root, f)\n",
    "                ext = os.path.splitext(fullname)[1]\n",
    "                self.doc_path[fullname]=ext\n",
    "        print(self.doc_path)        \n",
    "\n",
    "        \n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[Document]:\n",
    "        allDocs =[]\n",
    "        for key,value in self.doc_path.items():\n",
    "            #print(\"key:\"+key+\" value:\"+value)\n",
    "            if value == \".doc\":\n",
    "                word_loader = Docx2txtLoader(key)\n",
    "                word_document = word_loader.load()\n",
    "                allDocs.append(word_document)\n",
    "            elif value == \".txt\":\n",
    "                txt_loader = TextLoader(key)\n",
    "                txt_document = txt_loader.load()\n",
    "                allDocs.append(txt_document)\n",
    "            elif value == \".pdf\":\n",
    "                pdf_loader = PyPDFLoader(self.doc_path)\n",
    "                pdf_document = pdf_loader.load()\n",
    "                allDocs.append(pdf_document)\n",
    "            else:\n",
    "                pass\n",
    "        return allDocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0efdcb3-70ad-43d0-b1a4-c4b14154cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./docs/aws_emr.txt': '.txt', './docs/aws_cleanroom.txt': '.txt', './docs/.ipynb_checkpoints/aws_cleanroom-checkpoint.txt': '.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "import os\n",
    "\n",
    "\n",
    "retriever = FullContentRetriever()\n",
    "retriever._get_content_type(\"./docs\")\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search enterprise documents\",\n",
    "    \"useful for when you need to retreve documents regarding the user's question\",\n",
    ")\n",
    "os.environ[\"SERPAPI_API_KEY\"]=\"e94267b343a2985d25d7a9a65e1b31a6629a4b4860872c927b33c88674fa89d2\"\n",
    "search = SerpAPIWrapper()\n",
    "search_tool = Tool(\n",
    "    name=\"search website\",\n",
    "    func=search.run,\n",
    "    description=\"useful for when you need to answer questions by searching the website\",\n",
    ")\n",
    "custom_tool_list = [retriever_tool,search_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c161d0c-c455-422b-90c8-03773c0be11b",
   "metadata": {},
   "source": [
    "## 测试tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f2c46ac-8415-4c8a-a489-55cf59cf3048",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      " Here is how I would answer the question about AWS Clean Rooms pricing:\n",
      "\n",
      "Question: AWS Clean Rooms怎么收费的?\n",
      "Thought: Since this is a question about AWS pricing, I should search AWS documentation for information on Clean Rooms pricing.\n",
      "Action: search enterprise documents\n",
      "Action Input: \"AWS Clean Rooms pricing\"\u001b[32;1m\u001b[1;3m Here is how I would answer the question about AWS Clean Rooms pricing:\n",
      "\n",
      "Question: AWS Clean Rooms怎么收费的?\n",
      "Thought: Since this is a question about AWS pricing, I should search AWS documentation for information on Clean Rooms pricing.\n",
      "Action: search enterprise documents\n",
      "Action Input: \"AWS Clean Rooms pricing\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[[Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/aws_emr.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/aws_cleanroom.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/.ipynb_checkpoints/aws_cleanroom-checkpoint.txt'})]]\u001b[0m\n",
      "Thought: Based on the documents, it looks like AWS Clean Rooms is charged based on CRPU-hour usage. The key points are:\n",
      "\n",
      "- Pricing is $0.656 per CRPU-hour\n",
      "- Each query defaults to 32 CRPUs \n",
      "- Minimum billing duration is 1 minute\n",
      "- For the first 12 months, there is a free tier of 9 CRPU hours per month\n",
      "\n",
      "To calculate the cost of a query:\n",
      "\n",
      "- Query duration is rounded up to nearest minute, e.g. a 45 second query would be 1 minute \n",
      "- Multiply query duration in hours by 32 CRPUs\n",
      "- Multiply the CRPU-hours by $0.656 per CRPU-hour\n",
      "\n",
      "For example, if a query takes 2 minutes (0.033 hours), the cost would be:\n",
      "\n",
      "(0.033 hours * 32 CRPUs) * $0.656 per CRPU-hour = $0.68\n",
      "\n",
      "The CRPU-hour usage can be viewed in the AWS Billing console under Usage Quantity.\n",
      "\n",
      "Thought: I now know the details of how AWS Clean Rooms is charged based on the provided information.\n",
      "\n",
      "Final Answer: AWS Clean Rooms is charged based on CRPU-hour usage at a rate of $0.656 per CRPU-hour. The cost of a query is calculated by multiplying the query duration in hours (rounded up to the nearest minute) by 32 CRPUs, and then multiplying the CRPU-hours by the per CRPU-hour price. Usage and costs can be viewed in the AWS Billing console.\u001b[32;1m\u001b[1;3m Based on the documents, it looks like AWS Clean Rooms is charged based on CRPU-hour usage. The key points are:\n",
      "\n",
      "- Pricing is $0.656 per CRPU-hour\n",
      "- Each query defaults to 32 CRPUs \n",
      "- Minimum billing duration is 1 minute\n",
      "- For the first 12 months, there is a free tier of 9 CRPU hours per month\n",
      "\n",
      "To calculate the cost of a query:\n",
      "\n",
      "- Query duration is rounded up to nearest minute, e.g. a 45 second query would be 1 minute \n",
      "- Multiply query duration in hours by 32 CRPUs\n",
      "- Multiply the CRPU-hours by $0.656 per CRPU-hour\n",
      "\n",
      "For example, if a query takes 2 minutes (0.033 hours), the cost would be:\n",
      "\n",
      "(0.033 hours * 32 CRPUs) * $0.656 per CRPU-hour = $0.68\n",
      "\n",
      "The CRPU-hour usage can be viewed in the AWS Billing console under Usage Quantity.\n",
      "\n",
      "Thought: I now know the details of how AWS Clean Rooms is charged based on the provided information.\n",
      "\n",
      "Final Answer: AWS Clean Rooms is charged based on CRPU-hour usage at a rate of $0.656 per CRPU-hour. The cost of a query is calculated by multiplying the query duration in hours (rounded up to the nearest minute) by 32 CRPUs, and then multiplying the CRPU-hours by the per CRPU-hour price. Usage and costs can be viewed in the AWS Billing console.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AWS Clean Rooms is charged based on CRPU-hour usage at a rate of $0.656 per CRPU-hour. The cost of a query is calculated by multiplying the query duration in hours (rounded up to the nearest minute) by 32 CRPUs, and then multiplying the CRPU-hours by the per CRPU-hour price. Usage and costs can be viewed in the AWS Billing console.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.web_research import WebResearchRetriever\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain import LLMChain\n",
    "\n",
    "\n",
    "# Initialize search agent\n",
    "output_parser = CustomOutputParser()\n",
    "agent_executor = initialize_agent([retriever_tool], bedrock_llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         agent_kwargs={\n",
    "                            \"output_parser\": output_parser\n",
    "                         },\n",
    "                         verbose=True)\n",
    "agent_prompt=agent_executor.agent.llm_chain.prompt\n",
    "result=agent_executor.run(\"AWS Clean Rooms怎么收费的?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce7ba6f8-2365-442b-8298-b83e2b3cc3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      " Here is my response:\n",
      "\n",
      "Question: AWS EMR有哪些节点类型?\n",
      "Thought: To answer this, I should search for AWS EMR documentation that covers the different node types.\n",
      "Action: search enterprise documents\n",
      "Action Input: \"aws emr node types\"\u001b[32;1m\u001b[1;3m Here is my response:\n",
      "\n",
      "Question: AWS EMR有哪些节点类型?\n",
      "Thought: To answer this, I should search for AWS EMR documentation that covers the different node types.\n",
      "Action: search enterprise documents\n",
      "Action Input: \"aws emr node types\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[[Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/aws_emr.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/aws_cleanroom.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/.ipynb_checkpoints/aws_cleanroom-checkpoint.txt'})]]\u001b[0m\n",
      "Thought: Based on the provided documents, here are the key points about node types in AWS EMR:\n",
      "\n",
      "- Amazon EMR clusters consist of nodes such as master node, core node, and task node. \n",
      "\n",
      "- Master node manages the cluster and coordinates distribution of data and tasks among other nodes for processing. It tracks status of tasks and monitors health of the cluster.\n",
      "\n",
      "- Core node runs tasks and stores data in the Hadoop Distributed File System (HDFS) on the cluster. Multi-node clusters have at least one core node.\n",
      "\n",
      "- Task node runs only tasks but does not store data in HDFS. Task nodes are optional.\n",
      "\n",
      "So in summary, the main node types in AWS EMR are master node, core node, and task node, each serving different roles in the cluster.\n",
      "\n",
      "Thought: I have summarized the key node types in AWS EMR based on the provided enterprise documents.\n",
      "\n",
      "Final Answer: The main node types in AWS EMR are:\n",
      "\n",
      "- Master node - Manages the cluster and coordinates task distribution \n",
      "\n",
      "- Core node - Runs tasks and stores data in HDFS\n",
      "\n",
      "- Task node - Runs only tasks but does not store data\u001b[32;1m\u001b[1;3m Based on the provided documents, here are the key points about node types in AWS EMR:\n",
      "\n",
      "- Amazon EMR clusters consist of nodes such as master node, core node, and task node. \n",
      "\n",
      "- Master node manages the cluster and coordinates distribution of data and tasks among other nodes for processing. It tracks status of tasks and monitors health of the cluster.\n",
      "\n",
      "- Core node runs tasks and stores data in the Hadoop Distributed File System (HDFS) on the cluster. Multi-node clusters have at least one core node.\n",
      "\n",
      "- Task node runs only tasks but does not store data in HDFS. Task nodes are optional.\n",
      "\n",
      "So in summary, the main node types in AWS EMR are master node, core node, and task node, each serving different roles in the cluster.\n",
      "\n",
      "Thought: I have summarized the key node types in AWS EMR based on the provided enterprise documents.\n",
      "\n",
      "Final Answer: The main node types in AWS EMR are:\n",
      "\n",
      "- Master node - Manages the cluster and coordinates task distribution \n",
      "\n",
      "- Core node - Runs tasks and stores data in HDFS\n",
      "\n",
      "- Task node - Runs only tasks but does not store data\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "response=agent_executor.run(\"AWS EMR有哪些节点类型?\")\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044a62f-ded8-4f6a-ab80-afd27acb6ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del agent \n",
    "del agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33ad48-233a-4454-8e56-6460122f651c",
   "metadata": {},
   "source": [
    "## 测试agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47f717da-3846-4497-984b-c074aac0492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2,memory_key=\"chat_history\", input_key='input', output_key=\"output\")\n",
    "PREFIX = \"\"\"Answer the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "\n",
    "SUFFIX = \"\"\"Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "customerized_instructions=\"\"\"\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "These are guidance on when to use a tool to solve a task, follow them strictly:\n",
    " - first use \"search enterprise documents\" tool to retreve the document to answer if need\n",
    " - then use \"search website\" tool to search the latest website to answer if need\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "766bba4a-3b72-4c44-9d88-6ef0f9978a10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Question: 九寨沟明天天气如何?\n",
      "\n",
      "Thought: 要回答九寨沟明天的天气情况,我需要先在企业内部文件中搜索相关信息。\n",
      "\n",
      "Action: search enterprise documents\n",
      "Action Input: 九寨沟天气预报\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[[Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/aws_emr.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/aws_cleanroom.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/.ipynb_checkpoints/aws_cleanroom-checkpoint.txt'})]]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 对不起,我无法直接回答九寨沟明天的天气情况,因为我没有访问实时天气预报数据的能力。不过,我可以尝试搜索企业文档,看看是否有九寨沟地区的气候概况或天气特征相关的信息。如果没有找到相关信息,我会考虑搜索网站获得更多关于九寨沟天气的资讯。请给我下一步的指导。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 对不起,我无法直接回答九寨沟明天的天气情况,因为我没有访问实时天气预报数据的能力。不过,我可以尝试搜索企业文档,看看是否有九寨沟地区的气候概况或天气特征相关的信息。如果没有找到相关信息,我会考虑搜索网站获得更多关于九寨沟天气的资讯。请给我下一步的指导。'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "###step by step contstruct########\n",
    "#llm_chain = LLMChain(llm=bedrock_llm)\n",
    "#agent = ZeroShotAgent(llm_chain=llm_chain, tools=custom_tool_list, verbose=True)\n",
    "#agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "#    agent=agent, tools=custom_tool_list, verbose=True, memory=memory\n",
    "#)\n",
    "#agent_chain.run(\"最近最火的电影是什么？\")\n",
    "##quick construct#####\n",
    "agent_executor = initialize_agent(custom_tool_list, bedrock_llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                                  verbose=True,max_iterations=5,\n",
    "                                  handle_parsing_errors=True,\n",
    "                                  memory=memory,\n",
    "                                  agent_kwargs={\n",
    "                                      \"output_parser\": output_parser,\n",
    "                                      #'prefix':PREFIX,\n",
    "                                      #'suffix':SUFFIX,\n",
    "                                      'format_instructions':customerized_instructions\n",
    "                                           }\n",
    "                                 )\n",
    "#agent_executor.agent.llm_chain.prompt.template\n",
    "agent_executor.run(\"九寨沟明天天气如何?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ac9f7f6-137a-4899-8841-8cdc937c1514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_executor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m agent_executor\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m memory\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent_executor' is not defined"
     ]
    }
   ],
   "source": [
    "del agent_executor\n",
    "del memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c922805-37ea-4055-9a9c-c725d4c77f3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ui demo 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27637a-0b94-4f23-8f28-f75867cfa7c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./docs/aws_emr.txt': '.txt', './docs/aws_cleanroom.txt': '.txt', './docs/.ipynb_checkpoints/aws_cleanroom-checkpoint.txt': '.txt'}\n",
      "Create new client\n",
      "  Using region: us-west-2\n",
      "  Using profile: default\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/layouts/column.py:55: UserWarning: 'scale' value should be an integer. Using 4.5 will cause issues.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/layouts/column.py:55: UserWarning: 'scale' value should be an integer. Using 5.5 will cause issues.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/blocks.py:902: UserWarning: api_name execute_agent already exists, using execute_agent_1\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "4.0.2\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://d68c558378c4aacde5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "临时文件夹地址：./tmp/tmph7nn1lrd\n",
      "上传文件的地址：/tmp/gradio/27870540f7d37abc0f2ee0178b3c2fdd3949851c/aws_emr.txt\n",
      "./tmp/tmph7nn1lrd/aws_emr.txt\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Question: 我想让你担任职业顾问。我将为您提供一个在职业生涯中寻求指导的人,您的任务是帮助他们根据自己的技能、兴趣和经验确定最适合的职业。您还应该对可用的各种选项进行研究,解释不同行业的就业市场趋势,并就哪些资格对追求特定领域有益提出建议。我的第一个请求是\n",
      "AWS EMR怎么收费?\n",
      "\n",
      "Thought: Since the question is about how AWS EMR charges fees, I will search enterprise documents first to find relevant information.\n",
      "\n",
      "Action: search enterprise documents\n",
      "Action Input: AWS EMR pricing\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[[Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/aws_emr.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/aws_cleanroom.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/.ipynb_checkpoints/aws_cleanroom-checkpoint.txt'})]]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Based on the documents retrieved, here are the key points about how AWS EMR charges fees:\n",
      "\n",
      "- AWS EMR pricing is based on the EC2 instance types and number of instances you deploy for your cluster, as well as the AWS region where you launch the cluster. \n",
      "\n",
      "- On-demand pricing provides low hourly rates, but you can further reduce costs by purchasing Reserved Instances or Spot Instances. Spot instances can significantly reduce costs, sometimes to as low as 10% of on-demand pricing.\n",
      "\n",
      "- If you use Amazon S3, Amazon Kinesis or DynamoDB with your EMR cluster, there will be additional charges for those services separate from your EMR usage charges. \n",
      "\n",
      "- If you have your EMR cluster in a private subnet, it's recommended to set up a VPC endpoint for Amazon S3 as well, otherwise you'll be charged for NAT Gateways for the traffic between EMR and S3.\n",
      "\n",
      "- You can optimize costs by auto-scaling clusters up and down based on workload, and by using a mix of on-demand and spot instances. Spot instances can provide significant savings but may be terminated if spot prices change.\n",
      "\n",
      "In summary, the key factors are:\n",
      "- EC2 instance type and number\n",
      "- On-demand vs spot vs reserved pricing\n",
      "- Additional charges for other integrated AWS services \n",
      "- Auto-scaling to match workloads\n",
      "- VPC setup and data transfer charges\n",
      "\n",
      "So in optimizing AWS EMR costs, focus on right-sizing clusters, utilizing spot instances intelligently, and minimizing data transfer between services.\n",
      "\n",
      "Final Answer: AWS EMR pricing is based primarily on the EC2 instances used for the cluster, with options to reduce costs through spot instances and auto-scaling. Additional charges may apply for using other AWS services like S3 and Kinesis. Cost optimization involves right-sizing clusters, using spot instances, and minimizing data transfer between services.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m 我理解您最近感到很疲惫,需要一个假期来放松和恢复精力。这很正常,每个人都需要定期休息一下。\n",
      "\n",
      "在考虑休假前,我建议您先反思一下导致疲惫的原因。是工作量太大吗?还是压力太大?找到根源,然后考虑如何处理。也许可以调整一下工作方式,提高效率,或者与领导商讨调整工作内容。如果是压力太大,不妨找个人倾诉,或者做做冥想,锻炼身体。\n",
      "\n",
      "休假确实能让人放松身心,我建议您规划一个合适的假期。不要完全断联工作,但也要给自己足够的时间来恢复活力。在假期中,可以做一些您平时喜欢但来不及做的事情。多出去走走,呼吸新鲜空气,也有助放松。 \n",
      "\n",
      "最后,休假后的重要一步是继续保持积极的心态。把休假看作是一个新的开始,制定好工作和生活计划,保持积极和努力的态度。相信您能重新振作起来,继续投入工作。如果仍感到疲惫,也不要勉强,与领导商量后再考虑下一步。\n",
      "\n",
      "希望这些建议对您有帮助。休息对身心都很重要,合理规划假期,做好恢复准备,一定能让您重新焕发活力!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "^C\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://d68c558378c4aacde5.gradio.live\n"
     ]
    }
   ],
   "source": [
    "!python ./demo_ui.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf6a07-cb4a-482f-8f5b-2ef4fd3aecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UI local test####\n",
    "!python ./demo_table_ui.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
