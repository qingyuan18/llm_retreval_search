{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1a0a0-6eec-471e-ab0d-d6a30498bee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###UI local test####\n",
    "!python ./demo_table_ui.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea2cd6-c36c-464d-a916-1ef05f6e24b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list|grep -i langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8acaa4-7ded-4da3-935d-dd71ba029a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pypdf\n",
    "#!pip install langchain\n",
    "#!pip install gradio\n",
    "#!pip install docx2txt\n",
    "#!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48179687-b1d3-4073-bbd5-f99c1947e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.agents import Tool, AgentExecutor, AgentOutputParser\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "\n",
    "\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    runtime: Optional[bool] = True,\n",
    "):\n",
    "  \n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "        \n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    client_kwargs[\"aws_access_key_id\"] = os.environ.get(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "    client_kwargs[\"aws_secret_access_key\"] = os.environ.get(\"AWS_SECRET_ACCESS_KEY\",\"\")\n",
    "    \n",
    "    bedrock_client = session.client(\n",
    "        service_name=service_name,\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client\n",
    "\n",
    "\n",
    "\n",
    "## for aksk bedrock\n",
    "def get_bedrock_aksk(secret_name='chatbot_bedrock', region_name = \"us-west-2\"):\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = json.loads(get_secret_value_response['SecretString'])\n",
    "    return secret['BEDROCK_ACCESS_KEY'],secret['BEDROCK_SECRET_KEY']\n",
    "\n",
    "ACCESS_KEY, SECRET_KEY=get_bedrock_aksk()\n",
    "\n",
    "#role based initial client#######\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"  # E.g. \"us-east-1\"\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "#os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\"  # E.g. \"arn:aws:...\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=ACCESS_KEY\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=SECRET_KEY\n",
    "\n",
    "\n",
    "#新boto3 sdk只能session方式初始化bedrock\n",
    "boto3_bedrock = get_bedrock_client(\n",
    "    #assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "parameters_bedrock = {\n",
    "    \"max_tokens_to_sample\": 2048,\n",
    "    #\"temperature\": 0.5,\n",
    "    \"temperature\": 0,\n",
    "    #\"top_k\": 250,\n",
    "    #\"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs=parameters_bedrock)\n",
    "###test the bedrock langchain integration###\n",
    "#bedrock_llm.predict(\"Human:how do you describe LLM?\\n\"+\n",
    "#           \"Assistant:\")\n",
    "\n",
    "class BedrockModelWrapper(Bedrock):\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        prompt = \"\\nHuman: \\n\" + prompt + \"\\nAssistant:\"   ## Satisfy Bedrock-Claude prompt requirements\n",
    "        return super()._call(prompt, stop, run_manager, **kwargs)\n",
    "\n",
    "\n",
    "bedrock_llm_additional = BedrockModelWrapper(model_id=\"anthropic.claude-v2\", \n",
    "                                          client=boto3_bedrock, \n",
    "                                          model_kwargs=parameters_bedrock)\n",
    "\n",
    "\n",
    "##use customerized outputparse to fix claude not match \n",
    "##langchain's openai ReAct template don't have \n",
    "##final answer issue \n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        #print(\"cur step's llm_output ===\"+llm_output)\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output},\n",
    "                log=llm_output,\n",
    "            )\n",
    "            #raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bfce2-6f96-46c8-94df-048d9b27069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "import os\n",
    "from typing import Dict\n",
    "from typing import Any, Dict, List, Optional,Union\n",
    "\n",
    "\n",
    "\n",
    "class FullContentRetriever(BaseRetriever):\n",
    "    doc_path={}\n",
    "    def _get_content_type(self,doc_path:str):\n",
    "        fullname=\"\"\n",
    "        for root, dirs, files in os.walk(doc_path):\n",
    "            for f in files:\n",
    "                fullname = os.path.join(root, f)\n",
    "                ext = os.path.splitext(fullname)[1]\n",
    "                self.doc_path[fullname]=ext\n",
    "        print(self.doc_path)        \n",
    "\n",
    "        \n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[Document]:\n",
    "        allDocs =[]\n",
    "        for key,value in self.doc_path.items():\n",
    "            #print(\"key:\"+key+\" value:\"+value)\n",
    "            if value == \".doc\":\n",
    "                word_loader = Docx2txtLoader(key)\n",
    "                word_document = word_loader.load()\n",
    "                allDocs.append(word_document)\n",
    "            elif value == \".txt\":\n",
    "                txt_loader = TextLoader(key)\n",
    "                txt_document = txt_loader.load()\n",
    "                allDocs.append(txt_document)\n",
    "            elif value == \".pdf\":\n",
    "                pdf_loader = PyPDFLoader(self.doc_path)\n",
    "                pdf_document = pdf_loader.load()\n",
    "                allDocs.append(pdf_document)\n",
    "            else:\n",
    "                pass\n",
    "        return allDocs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "retriever = FullContentRetriever()\n",
    "retriever._get_content_type(\"./docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efdcb3-70ad-43d0-b1a4-c4b14154cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "import os\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"]=\"e94267b343a2985d25d7a9a65e1b31a6629a4b4860872c927b33c88674fa89d2\"\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search enterprise documents\",\n",
    "    \"useful for when you need to retreve documents regarding the user's question\",\n",
    ")\n",
    "search = SerpAPIWrapper()\n",
    "search_tool = Tool(\n",
    "    name=\"search website\",\n",
    "    func=search.run,\n",
    "    description=\"useful for when you need to answer questions by searching the website\",\n",
    ")\n",
    "custom_tool_list = [retriever_tool,search_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c161d0c-c455-422b-90c8-03773c0be11b",
   "metadata": {},
   "source": [
    "## 测试tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f2c46ac-8415-4c8a-a489-55cf59cf3048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Here is how I would answer the question about AWS Clean Rooms pricing:\n",
      "\n",
      "Question: AWS Clean Rooms怎么收费的?\n",
      "Thought: Since this is a question about AWS pricing, I should search AWS documentation for information on Clean Rooms pricing.\n",
      "Action: search enterprise documents\n",
      "Action Input: \"AWS Clean Rooms pricing\"\u001b[0mkey:./docs/aws_emr.txt value:.txt\n",
      "key:./docs/aws_cleanroom.txt value:.txt\n",
      "key:./docs/.ipynb_checkpoints/aws_emr-checkpoint.txt value:.txt\n",
      "[[Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/aws_emr.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/aws_cleanroom.txt'})], [Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/.ipynb_checkpoints/aws_emr-checkpoint.txt'})]]\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m[[Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/aws_emr.txt'})], [Document(page_content='Question: AWS Clean Rooms在中国区是否可用？\\nAnswer: 目前没有落地中国区的时间表，已经在以下区域推出：美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）\\n=====\\nQuestion: AWS Clean Rooms中，为什么在合成的小数据集上第一次查询的时候需要几分钟才返回？\\nAnswer: 第一次查询的时候是因为调度和拉起资源的影响，一般第二次查询就会变快。 但过一段时间后，资源释放后这个问题又会出现。在资源拉起期间是不进行收费的。\\n=====\\nQuestion: AWS Clean Rooms能支持多大规模数据的查询？查询速度怎么样？\\nAnswer: 能支持TB/GB级数据的查询。 一般查询延迟为几十秒到几分钟。默认计算容量为32 CRPUs, 目前这个默认计算容量不可设置，但是roadmap中未来打算让用户可以进行设置。(Slack中Ryan 提到，如果引擎中任务有积压，它能够scale up）\\n=====\\nQuestion: AWS Clean Rooms 是如何计费的？\\nAnswer: 按照CRPU-hour单价进行计费，每个查询默认计算容量为32 CRPUs。 金额 = (0.125 hours x 32 CRPUs * $0.656 per CRPU-hour) , 有1分钟的最小计费时间。头12个月内，会有9CRPU hours的免费额度。\\n=====\\nQuestion: AWS Clean Rooms 从哪里可以看到CRPU-hours的用量？\\nAnswer: AWS Clean Rooms 本身的workspace中无法查看，可以在AWS Billing/Bills 中查看Usage Quantity得到该信息。\\n=====\\nQuestion: AWS Clean Rooms目前可以支持什么数据源的接入？ \\nAnswer: 目前只支持S3，其他数据源近期没有具体计划。\\n=====\\nQuestion: AWS Clean Rooms一个协作中，最大的并发查询数是多少？\\nAnswer: 5个\\n=====\\nQuestion: 我们如何说服客户相信AWS Clean Rooms的安全性和正确性？我在这里的大多数合规计划中都看不到AWS Clean Rooms， https://aws.amazon.com/compliance/services-in-scope/ ？\\nAnswer: 正在加入这些合规计划的进程中。\\n=====\\nQuestion: AWS Clean Rooms的数据源必须在AWS上么？\\nAnswer: 对，目前必须在AWS上，而且必须是同一个region。\\n=====\\nQuestion: AWS Clean Rooms的数据是如何进入到S3？\\nAnswer: 需要数据的持有者，把数据上传到S3上，然后再用Glue爬去下，拿到表的schema。这样才能关联到AWS CleanRooms。\\n=====\\nQuestion: AWS Clean Rooms的这些安全控制权限只是作用与分析么？能够改动它方的数据么？\\nAnswer: 对，只作用于分析，不能修改对方数据\\n=====\\nQuestion: AWS Clean Rooms协作方的数据会移动么？协作方的原始数据会集中到AWS Clean Rooms吗？\\nAnswer: 在联合分析获取他方数据时数据存在移动，但协作方的原始数据并不会存住在clean room内，clean room并不是一个物理存贮空间。\\n=====\\nQuestion: AWS Clean Rooms中，是否发起者和数据贡献者都会被收费？\\nAnswer: 是单方收费，只有查询的接收方会进行收费。\\n=====\\nQuestion: AWS Clean Rooms的数据贡献方的S3， 会产生API会产生调用次数收费么？\\nAnswer: 会， Glue Data Catalog API 的调用也会被收费， 如果加密数据用了KMS-CMK也会被相应的收费。\\n=====\\nQuestion: AWS Clean Rooms使用时，是否有一个强约束，两方的数据中一定要一个join字段才能够进行分析？\\nAnswer: List 和Aggregation两种不同的分析规则下有区别， List 只能支持重合用户的，所以必须要有关联字段。Aggregation可以支持你仅仅去查询对方的数据，这种情况下，是可以不指定关联字段的。\\n=====\\nQuestion: 如果已经在用Athena，S3桶中已经有数据了，是否能基于S3中这个数据就地加入AWS Clean Room?\\nAnswer: 是的，就地就能加入clean room, 这个S3桶就是一般的S3桶，并没有任何特殊。但这个S3路径不能注册到AWS Lake Formation中。\\n=====\\nQuestion: 是否能通过SDK也就是代码来调用AWS Clean Rooms的联合分析\\nAnswer: 可以，可以参考代码 https://gitlab.aws.dev/rmalecky/aws-clean-rooms-notebooks/-/blob/main/single_collaborator_aggregation.ipynb。\\n=====\\nQuestion: AWS Clean Rooms在输出分析结果的时候，能否按照字段进行分区？\\nAnswer: 目前不能。\\n=====\\nQuestion: AWS Clean Rooms最大的参与方是多少？ 如果超过了限制怎么办？\\nAnswer: 目前5个参与方为最大限制，这个是软性的限制，slack频道中有披露最大支持的硬限制为10。\\n=====\\nQuestion: AWS clean rooms 用的什么加密算法？\\nAnswer: C3R，是aws开源加密代码库。提供了C3R Client(一个可执行的Jar包)，目前仅支持对csv和parquet文件格式进行加密，后续可能会支持更多格式。 由于clean room把所有的字段分成三种类型： 指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column), 他们的加密方式有所不同，C3R client 会使用AES-GCM加密算法对sealed字段进行加密，会使用HMAC(Hash-based Message Authentication Code)来对fingerprint字段进行加密。\\n=====\\nQuestion: AWS Clean Rooms加密过程中有密文落地么？如果有，密文存在哪里？\\nAnswer: 由于C3R是客户端加密，所以clean room 关联S3中的数据已经是加密后的密文。\\n=====\\nQuestion: 数据上传到S3的过程中，有两种加密方式Server Side 和 Client Side加密，如果客户的安全等级比较高，在数据上传之前做了加密，再想交给AWS Clean Rooms去处理，之前提到的C3R的加密方式，具体是一个怎么样的流程呢？\\nAnswer: 首先AWS Clean Rooms对于Server Side的加密是透明的，无需额外处理。AWS Clean Rooms不支持S3的客户端加密，必须采用C3R客户端进行加密，加密完成以后把数据上传到S3桶，后续流程和不加密的流程是一致的。 加密这步需要比较多的手工操作，包括：1) 加密前需要创建好collaboration(协作), 得到collaboration_id后续在加密中需要提供; 2) 利用openssl 生成32位密钥并分享给其他协作方; 3) 加密过程中需要指定哪些字段为指纹列(fingerprint column), 密封列(sealed column), 明文列(cleartext column)\\n=====\\nQuestion: AWS Clean Rooms在安全计算方面，应该归属哪一类？\\nAnswer: 应该属于Secure multi-party computation，从内部的roadmap中有提到会引入Differential Privacy (DP) 差分隐私技术。\\n=====\\nQuestion: AWS Clean Rooms是否所有的字段都可以进行加密？\\nAnswer: 对于sealed和 fingerprint字段，只有string字段类型被支持。对于csv文件，C3R的客户端处理任何值都作为UTF-8编码的文本，加密前不会做任何其他的前置处理。对于parquet文件，对sealed和 fingerprint字段，如果出现非string的字段，会直接报错。C3R 客户端不能处理parquet中的复杂字段比如struct。\\n=====\\nQuestion: AWS Clean Rooms如果要对某个字段进行求和，求平均的数据计算，是否可以加密？\\nAnswer: 不能，只能作为cleartext明文列。\\n=====\\nQuestion: AWS Clean Rooms如果想要通过某些字段进行where过滤，这些字段应该是什么类型？\\nAnswer: 只能是cleartext明文列。\\n=====\\nQuestion: C3R客户端是否有实现任何non-standard的加密算法?\\nAnswer: 基本都是标准化的算法，除了一个HKDF(一种密钥推导函数)的实现(来自RFC5869), 但是使用的是java标准加密库中的MAC算法。\\n=====\\nQuestion: AWS Clean rooms 与 AMC的区别与联系是什么？\\nAnswer: AMC是一个专门服务与Amazon Ads的clean room应用，它是并且将持续是唯一的服务于Amazon Ads客户的应用服务。AWS Clean Rooms 是一个云分析服务，会服务于各个行业的数据合作需求。2023年, AMC 将会把自己的查询引擎和计算基础设置迁移到AWS Clean Rooms服务，将会帮助AMC更方便的服务于客户(他们将不再需要把自己第一方数据上传到AMC，在AWS S3上即可使用)。\\n=====\\nQuestion: AWS Clean rooms 与 其他的clean room服务商的区别？\\nAnswer: AWS Clean rooms 覆盖的客户范围更广。而其他的服务商客户范围相对小，需要把数据移动到他们的平台上。AWS Clean rooms则无需数据移动。(Bastion 2021年announce的时候，其他的云厂商比如(google cloud 和 microsoft azure) 还没有通用场景的clean room solution，snowflake 有，功能上有区别，只允许data provider 提供预先固定的SQL，Bastion灵活性更好。snowflake要求数据必须进入他们的数仓，aws在S3 即可)。\\n=====\\nQuestion: AWS Clean Rooms有哪些典型的应用场景？\\nAnswer: 包含多个行业，下面提供部分参考: 1)广告营销领域, 广告营销活动中流量平台方需要给广告主或者营销方他们的广告点击数据和展现数据进行分析，但是不能提供用户级别的信息; 2)零售领域, 银行和零售商需要获取他们的重叠用户，用于进行联合的市场活动，但不要把客户的其他信息暴露给彼此; 3)医疗健康领域, 药厂和医院之间，药厂需要医院的病历数据； 药厂和外包的研发机构之间需要进行数据的共享\\n=====\\nQuestion: AWS Clean Rooms 的 data catalog 是如何实现的？ data sharing permission 是如何实现的？\\nAnswer: 都是利用了AWS Lake formation, AWS Clean Rooms 里 SQL中字段级别的限制约束，是通过一种new class of AWS Lake formation permission 来实现的。\\n=====\\nQuestion: 可以在哪些地方进行AWS Clean Rooms的联合分析？\\nAnswer: 可以在clean room 的 workspace， 也可以在Redshift workspace （Note: 从目前发布产品文档上并没有，但是说明背后的引擎就是redshift severless)。\\n=====\\nQuestion: AWS Clean Rooms中，数据提供方如何对联合分析的收益方进行收费，或者实现一个数据授权的合同？\\nAnswer: 需要通过AWS Data Exchange 来进行 （Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms 与 AWS Data Exchange 是什么关系？\\nAnswer: AWS Clean Rooms 可以通过AWS Data Exchange 去浏览和寻找可用数据的合作方。 他是AWS Data Exchange的更近一步的服务，提供了可控(多种约束限制)和可审计的数据合作方式。\\n=====\\nQuestion: AWS Clean Rooms中是否支持视图？\\nAnswer: 允许客户在clean room 创建视图，并且在AWS Clean Rooms中保存物化视图，一旦退出协作，AWS Lake formation permission 将会被撤销，这些物化视图会被删除。（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms如果数据合作方没有aws account，能否支持？\\nAnswer: 目前这个版本不支持，后续的版本可能会考虑（NBC Universal 希望对于没有aws账号另外一方的数据可用）。\\n=====\\nQuestion: AWS Clean Rooms是否能够支持这个协作中，仅仅允许指定运行固定的SQL？\\nAnswer: 可以，可以利用query template来做（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms可以让数据贡献者提供一些样例数据进行预览么？\\nAnswer: 可以这么做，可以提供一些没有任何约束的示例数据给用户（Note: 目前AWS Clean Rooms并没有体现）。\\n=====\\nQuestion: AWS Clean Rooms当一个数据贡献者的数据发生更新后会怎么样？\\nAnswer: 它是一种live的共享，任何更新会立刻反映到联合分析的结果中。\\n=====\\nQuestion: AWS Clean Rooms 未来有哪些前进的方向？\\nAnswer: 主要有四个方向：1) Identity matching 身份ID对齐 (Note: 目前这项在官方的PPT在有体现); 2) 对隐私攻击的防护， 有些查询即使是一些聚合分析，仍然可能探查到个人的信息: a. 限制访问同一块范围数据的query的数量。 b. 采用差分隐私(Differential Privacy) 结果中添加噪声(会影响分析的精度)，Morgen Stanley 作为这个功能的beta用户; 3) 机器学习，P&G 表现出这方面的需求， 应该也是基于表格数据的模型，可能是流失预测，人群聚类等场景; 4) 和DSP的集成，直接把激活用户ID给到对接的DSP，而不通过cleanroom的数据接收方;\\n=====\\nQuestion: Service Team 有哪些相关的同事？\\nAnswer: Horne, Bill <bgh@amazon.com>, Rababy, Bethany <rababyb@amazon.com>, Malecky, Ryan <rmalecky@amazon.com>, Malik, Mohsen <mmohsen@amazon.com>, Tanna, Shamir <tannas@amazon.com>。', metadata={'source': './docs/aws_cleanroom.txt'})], [Document(page_content='Question: Amazon EMR允许处理哪些类型的数据和业务情报工作负载？\\nAnswer: 使用Amazon EMR，您可以处理用于分析目的的数据和业务情报工作负载。\\n=====\\nQuestion: Amazon EMR允许将数据移出/移入到哪些AWS数据存储和数据库中？\\nAnswer: Amazon EMR允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如Amazon Simple Storage Service（Amazon S3）和Amazon DynamoDB。\\n=====\\nQuestion: Amazon EMR的教程在哪里可以找到？\\nAnswer: Amazon EMR的教程可以在Amazon EMR服务页面中找到，也可以在Amazon EMR管理指南中找到。\\n=====\\nQuestion: Amazon EMR集群由哪些组件构成？\\nAnswer: Amazon EMR集群由集群和节点组成。集群是Amazon Elastic Compute Cloud（Amazon EC2）实例的集合，集群中的每个实例称作节点。\\n=====\\nQuestion: Amazon EMR中的节点类型有哪些？\\nAnswer: Amazon EMR中的节点类型有主节点、核心节点和任务节点。\\n=====\\nQuestion: 主节点在Amazon EMR集群中的作用是什么？\\nAnswer: 主节点管理集群，它通过运行软件组件来协调在其它节点之间分配数据和任务的过程以便进行处理。主节点跟踪任务的状态并监控集群的运行状况。\\n=====\\nQuestion: 核心节点在Amazon EMR集群中的作用是什么？\\nAnswer: 核心节点具有运行任务并在集群上的Hadoop Distributed File System（HDFS）中存储数据的软件组件。多节点集群至少具有一个核心节点。\\n=====\\nQuestion: 任务节点在Amazon EMR集群中的作用是什么？\\nAnswer: 任务节点具有仅运行任务但不在HDFS中存储数据的软件组件。任务节点是可选的。\\n=====\\nQuestion: Amazon EMR集群的生命周期包括哪些状态？\\nAnswer: Amazon EMR集群的生命周期包括启动、运行、终止和终止后的状态。\\n=====\\nQuestion: 如何向Amazon EMR集群提交工作？\\nAnswer: 可以通过几个选项向Amazon EMR集群提交工作。一种方法是在创建集群时在函数中提供要完成的工作的完整定义，并将其指定为步骤。另一种方法是创建一个长时间运行的集群并使用Amazon EMR控制台、API或AWS CLI提交包含一个或多个任务的步骤。还可以创建一个集群，根据需要使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: 如何处理Amazon EMR集群中的数据？\\nAnswer: 要处理Amazon EMR集群中的数据，可以直接向已安装的应用程序提交任务或查询，或在集群中运行步骤。可以通过安全连接连接到主节点，并访问可用于直接在集群上运行的软件的接口和工具。还可以向Amazon EMR集群提交一个或多个有序的步骤，每个步骤都是一个工作单位，其中包含可由集群上安装的软件处理的数据操作指令。\\n=====\\nQuestion: Amazon EMR支持哪些框架和应用程序？\\nAnswer: Amazon EMR支持多种框架和应用程序，包括Hadoop、Spark、Presto、Hive、HBase、Flink、Zeppelin等。在启动集群时，用户需要选择要安装的框架和应用程序，以满足其数据处理需求。\\n=====\\nQuestion: 如何连接到Amazon EMR集群？\\nAnswer: 可以通过安全连接连接到Amazon EMR集群的主节点，并访问可用于直接在集群上运行的软件的接口和工具。可以使用SSH连接到主节点和其他节点，并使用安装的应用程序提供的界面以脚本或交互方式执行任务和提交查询。\\n=====\\nQuestion: Amazon EMR中的数据输入通常存储在哪里？\\nAnswer: Amazon EMR中的数据输入通常存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的文件中。\\n=====\\nQuestion: Amazon EMR中的步骤是如何运行的？\\nAnswer: Amazon EMR中的步骤按照提交请求的顺序运行。每个步骤的状态从PENDING（待处理）开始，第一个步骤启动时状态更改为RUNNING（正在运行），完成后状态更改为COMPLETED（已完成），然后序列中的下一个步骤启动，以此类推，直到所有步骤完成。\\n=====\\nQuestion: 当Amazon EMR中的步骤失败时，其状态会如何更改？\\nAnswer: 当Amazon EMR中的步骤失败时，其状态会更改为FAILED（失败）。您可以选择忽略失败并允许继续执行其余步骤，或者立即终止集群。\\n=====\\nQuestion: Amazon EMR集群的生命周期是什么？\\nAnswer: 成功的Amazon EMR集群会遵循以下流程：首先为每个实例预置EC2实例，然后运行引导操作，在每个实例上安装本机应用程序，最后集群状态为RUNNING。在此期间，您可以连接到集群实例，集群将按顺序运行在创建集群时指定的任何步骤。\\n=====\\nQuestion: Amazon EMR如何处理数据？\\nAnswer: 在Amazon EMR中处理数据时，输入为以文件形式存储在您选择的底层文件系统（如 Amazon S3或HDFS）中的数据。数据从处理序列中的一个步骤传递到下一个。最后一步将输出数据写入指定位置，如Amazon S3存储桶。\\n=====\\nQuestion: 集群何时进入WAITING状态？\\nAnswer: 集群在成功运行步骤后进入WAITING状态。\\n=====\\nQuestion: 集群何时进入TERMINATING状态？\\nAnswer: 如果集群配置为在完成最后一个步骤后自动终止，则会进入TERMINATING状态。\\n=====\\nQuestion: 集群何时进入TERMINATED状态？\\nAnswer: 集群在进入TERMINATING状态后会进入TERMINATED状态。\\n=====\\nQuestion: 如何手动关闭集群？\\nAnswer: 如果集群配置为等待，您必须在不再需要它时手动将其关闭。\\n=====\\nQuestion: 集群生命周期中的故障会导致什么？\\nAnswer: 集群生命周期中的故障将导致Amazon EMR终止集群及其所有实例，除非您启用了终止保护。\\n=====\\nQuestion: 如何检索由于故障而终止的集群中的数据？\\nAnswer: 如果启用了终止保护，您可以从集群中检索数据，然后删除终止保护并终止集群。\\n=====\\nQuestion: Amazon EMR有哪些优势？\\nAnswer: Amazon EMR有以下优势：节省成本、AWS集成、部署、可扩展性和灵活度、可靠性、安全性和监控。\\n=====\\nQuestion: Amazon EMR如何节省成本？\\nAnswer: Amazon EMR可以根据您的需求自动启动和停止实例，从而最大程度地减少了成本。\\n=====\\nQuestion: Amazon EMR如何保证可靠性？\\nAnswer: Amazon EMR使用多个实例来运行作业，从而提高了可靠性。如果一个实例出现故障，其他实例可以继续工作。\\n=====\\nQuestion: Amazon EMR如何保证安全性？\\nAnswer: Amazon EMR提供了多种安全功能，例如加密、身份验证和访问控制，以保护您的数据和集群。\\n=====\\nQuestion: Amazon EMR 的定价取决于哪些因素？\\nAnswer: Amazon EMR 的定价取决于您部署的 Amazon EC2 实例的实例类型和数量及您启动集群的区域。按需定价提供很低的费率，但您可以通过购买预留实例或竞价型实例来进一步降低成本。Spot 实例可以显著节省成本，在某些情况下，低至按需定价的十分之一。\\n=====\\nQuestion: 如果我为 EMR 集群使用 Amazon S3、Amazon Kinesis 或 DynamoDB，会产生额外费用吗？\\nAnswer: 是的，这些服务会产生额外费用 - 与您的 Amazon EMR 使用费分开计费。\\n=====\\nQuestion: 如果我在私有子网中设置 Amazon EMR 集群，需要为 Amazon S3 设置什么？\\nAnswer: 我们建议您也为 Amazon S3 设置 VPC 端点。如果您的 EMR 集群处于没有适用于 Amazon S3 的 VPC 端点的私有子网中，则您需要为与 S3 流量关联的其他 NAT 网关付费，因为您的 EMR 集群与 S3 之间的流量不是位于您的 VPC 内。\\n=====\\nQuestion: Amazon EMR 可以与哪些 AWS 服务集成？\\nAnswer: Amazon EMR 可以与多个 AWS 服务集成，包括 Amazon EC2、Amazon Virtual Private Cloud（Amazon VPC）、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management（IAM）、AWS CloudTrail、AWS Data Pipeline、AWS Lake Formation 等。\\n=====\\nQuestion: Amazon EMR 集群由哪些实例组成？\\nAnswer: 您的 EMR 集群由 EC2 实例组成，这些实例执行您提交给集群的工作。\\n=====\\nQuestion: 如何为集群选择最适合处理需求的实例大小和类型？\\nAnswer: 您可以为集群选择最适合处理需求的实例大小和类型，包括批处理、低延迟查询、流数据或大数据存储。有关 Amazon EMR 实例类型的更多信息，请参阅配置集群硬件和联网。\\n=====\\nQuestion: Amazon EMR 可以如何灵活扩缩集群？\\nAnswer: Amazon EMR 可以根据您的计算需求变化灵活扩缩集群。您可以调整集群，在工作负载高峰时增加实例，在工作负载高峰过后移除实例，从而控制成本。有关更多信息，请参阅手动调整正在运行的集群的大小。\\n=====\\nQuestion: Amazon EMR提供了哪些实例类型选项？\\nAnswer: Amazon EMR提供了按需实例和竞价型实例两种选项。您可以在一个组中使用按需实例来保障处理能力，同时在另一个组中使用竞价型实例来加快任务完成速度并降低成本。您还可以混合多种实例类型以充分利用某种竞价型实例类型的定价优势。\\n=====\\nQuestion: Amazon EMR支持哪些文件系统？\\nAnswer: Amazon EMR可以为您的输入、输出和中间数据灵活使用多种文件系统。例如，对于不需要在集群生命周期之外存储的处理数据，您可以选择在集群的主节点和核心节点上运行的Hadoop Distributed File System（HDFS）。您可以选择EMR文件系统（EMRFS），将Amazon S3用作在集群上运行的应用程序的数据层，以便分离计算和存储，并在集群生命周期之外保留数据。EMRFS具备更多优势，可供您独立扩展或收缩计算和存储需求。\\n=====\\nQuestion: Amazon EMR如何保证集群的可靠性？\\nAnswer: Amazon EMR能够监控集群中的节点并自动终止和替换出现故障的实例。此外，您还可以配置终止保护，以防止集群中的实例由于处理期间出现的错误或问题而终止。如果启用终止保护，您可以在终止前从实例恢复数据。\\n=====\\nQuestion: Amazon EMR如何保护集群和数据的安全？\\nAnswer: Amazon EMR利用其它AWS服务（如IAM和Amazon VPC）和功能（如Amazon EC2密钥对）来帮助您保护集群和数据。Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。Amazon EMR还使用安全组控制EC2实例的入站和出站流量。Amazon EMR通过EMRFS支持可选的Amazon S3服务器端和客户端加密，以帮助保护您在Amazon S3中存储的数据的安全。\\n=====\\nQuestion: Amazon EMR如何配置集群终止方式？\\nAnswer: Amazon EMR提供了控制集群终止方式（自动或手动）的配置选项。如果您将集群配置为自动终止，则集群会在所有步骤完成后终止。这称作暂时性集群。不过，您可以将集群配置为在处理完成后继续运行，这样，当您不再需要它时，可以选择手动终止集群。或者，您可以创建一个集群，与所安装的应用程序直接交互，然后在不再需要时手动将其终止。这些示例中的集群称作长时间运行的集群。\\n=====\\nQuestion: Amazon EMR如何与IAM配合使用？\\nAnswer: Amazon EMR与IAM集成以管理权限。您可以使用IAM策略定义权限，并将其附加到用户或IAM组。您在策略中定义的权限确定了这些用户或组成员能够执行的操作及其能够访问的资源。此外，Amazon EMR为Amazon EMR服务本身使用IAM角色，为实例使用EC2实例配置文件。这些角色授予服务和实例代表您访问其它AWS服务的权限。\\n=====\\nQuestion: Amazon EMR支持在哪种隔离的虚拟网络中启动集群？\\nAnswer: Amazon EMR支持在Amazon VPC中的Virtual Private Cloud（VPC）中启动集群。\\n=====\\nQuestion: Amazon EMR集成哪个服务可以记录有关您的账户或代表您的AWS账户发起的请求的信息？\\nAnswer: Amazon EMR集成CloudTrail可以记录有关您的账户或代表您的AWS账户发起的请求的信息。\\n=====\\nQuestion: Amazon EMR支持哪些SDK？\\nAnswer: Amazon EMR目前在可用于以下SDK：Go、Java、.NET（C#和VB.NET）、Node.js、PHP、Python和Ruby。\\n=====\\nQuestion: Amazon EMR提供哪些可以和Amazon EMR交互的方式？\\nAnswer: Amazon EMR提供多种可以和Amazon EMR交互的方式，包括控制台、AWS Command Line Interface（AWS CLI）、软件开发工具包（SDK）和Web服务API。\\n=====\\nQuestion: Amazon EMR架构概览中包括哪些层？\\nAnswer: Amazon EMR服务架构包括多个层，每个层为集群提供特定的功能。这些层包括Amazon EC2、Amazon S3、Hadoop、YARN、Hive、Pig、Spark、Zeppelin、Ganglia和EMR Management。\\n=====\\nQuestion: 什么是Amazon EMR的存储层？\\nAnswer: Amazon EMR的存储层包含可用于集群的不同的文件系统，包括Hadoop Distributed File System（HDFS）、EMR 文件系统（EMRFS）和本地文件系统。\\n=====\\nQuestion: Hadoop Distributed File System（HDFS）是什么？\\nAnswer: Hadoop Distributed File System（HDFS）是一种分布式、可扩展的文件系统，供 Hadoop 使用。HDFS 将它所存储的数据在集群中的实例之间进行分配，从而在不同的实例上存储多份数据副本，确保在单个实例发生故障的情况下不会出现数据的丢失。\\n=====\\nQuestion: 什么是EMR 文件系统（EMRFS）？\\nAnswer: 借助 EMR 文件系统（EMRFS），Amazon EMR 可使 Hadoop 具备直接访问存储在 Amazon S3 中的数据（就像使用 HDFS 文件系统时一样）的功能。在集群中，您可以将 HDFS 或 Amazon S3 用作文件系统。Amazon S3 最常用于存储 HDFS 中存储的输入和输出数据以及中间结果。\\n=====\\nQuestion: 什么是本地文件系统？\\nAnswer: 本地文件系统指的是本地连接的磁盘。创建 Hadoop 集群时，会从 Amazon EC2 实例上创建各个节点，这些节点附带了预先配置的数据块，这些数据块属于称为实例存储的预先附加的磁盘存储。实例存储卷上的数据仅在 Amazon EC2 实例的生命周期内保留。\\n=====\\nQuestion: Amazon EMR的资源管理层负责什么？\\nAnswer: 资源管理层负责管理集群资源和调度作业，以进行数据处理。默认情况下，Amazon EMR 使用 YARN（Yet Another Resource Negotiator，Apache Hadoop 2.0 中引入的一个组件）集中管理多个数据处理框架的集群资源。\\n=====\\nQuestion: Amazon EMR的数据处理框架层是什么？\\nAnswer: 数据处理框架层是用于分析和处理数据的引擎。可在 YARN 上运行并具有自己的资源管理功能的框架有很多。不同的框架适用于不同类型的处理需求，如批处理、交互式处理、内存中处理、流式处理等。\\n=====\\nQuestion: Amazon EMR支持哪些主要处理框架？\\nAnswer: Amazon EMR支持Hadoop MapReduce和Apache Spark这两个主要处理框架。\\n=====\\nQuestion: Hadoop MapReduce是什么？\\nAnswer: Hadoop MapReduce是一种用于分布式计算的开源编程模型，它通过处理除Map-Reduce功能外的所有逻辑简化了编写平行分布式应用程序的过程。\\n=====\\nQuestion: Map函数和Reduce函数在Hadoop MapReduce中的作用是什么？\\nAnswer: Map函数将数据映射到一系列称为中间结果的键值对上，而Reduce函数则汇总这些中间结果、应用其它计算法并生成最终输出。\\n=====\\nQuestion: Apache Spark是什么？\\nAnswer: Apache Spark是一种用于处理大数据工作负载的集群框架和编程模型，它使用有向无环图来执行计划，使用内存缓存来处理数据集。\\n=====\\nQuestion: 在Amazon EMR上运行Spark时，可以直接访问哪个存储服务中的数据？\\nAnswer: 在Amazon EMR上运行Spark时，可以使用EMRFS直接访问Amazon S3中的数据。\\n=====\\nQuestion: Amazon EMR支持哪些应用程序？\\nAnswer: Amazon EMR支持许多应用程序，如Hive、Pig和Spark Streaming库，以提供使用更高级的语言创建处理工作负载、运用机器学习算法、制作流处理应用程序、构建数据仓库等功能。\\n=====\\nQuestion: 可以使用哪些库和语言与在Amazon EMR中运行的应用程序交互？\\nAnswer: 可以使用多种库和语言与在Amazon EMR中运行的应用程序交互，例如Java、Hive、Pig、Spark Streaming、Spark SQL、mLLib和GraphX等。\\n=====\\nQuestion: 如何设置Amazon EMR？\\nAnswer: 在首次启动Amazon EMR集群之前，需要注册AWS账户并完成一些任务，如创建管理用户和启用多重身份验证等。\\n=====\\nQuestion: 如何注册AWS账户？\\nAnswer: 您可以打开https://portal.aws.amazon.com/billing/signup并按照屏幕上的说明进行操作来注册AWS账户。在注册时，您将接到一通电话，要求您使用电话键盘输入一个验证码。\\n=====\\nQuestion: 什么是AWS账户根用户？\\nAnswer: 当您注册AWS账户时，系统将会创建一个AWS账户根用户。根用户有权访问该账户中的所有AWS服务和资源。\\n=====\\nQuestion: 为什么需要创建管理用户？\\nAnswer: 创建管理用户可以避免使用根用户执行日常任务，从而保护您的AWS账户根用户。\\n=====\\nQuestion: 如何保护AWS账户根用户？\\nAnswer: 您可以对您的根用户启用多重身份验证(MFA)来保护您的AWS账户根用户。\\n=====\\nQuestion: 如何为管理用户授予管理访问权限？\\nAnswer: 对于您的日常管理任务，请在AWS IAM Identity Center中为管理用户授予管理访问权限。\\n=====\\nQuestion: 如何使用IAM Identity Center用户身份登录？\\nAnswer: 要使用您的IAM Identity Center用户身份登录，请使用您在创建IAM Identity Center用户时发送到您的电子邮件地址的登录URL。\\n=====\\nQuestion: 什么是Amazon EMR？\\nAnswer: Amazon EMR是一个托管集群平台，可简化在上运行大数据框架（如 Apache Hadoop  和 Apache Spark ）的过程，AWS以处理和分析海量数据。\\n', metadata={'source': './docs/.ipynb_checkpoints/aws_emr-checkpoint.txt'})]]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Based on searching the enterprise documents, I was not able to find specific information on AWS Clean Rooms pricing. However, here is what I have gathered:\n",
      "\n",
      "- AWS Clean Rooms is charged based on CRPU-hour usage. Each query defaults to 32 CRPUs.\n",
      "\n",
      "- There is a minimum billing duration of 1 minute. \n",
      "\n",
      "- The current price per CRPU-hour is $0.656. \n",
      "\n",
      "- So a typical query would cost: (0.125 hours x 32 CRPUs x $0.656 per CRPU-hour) = $2.56\n",
      "\n",
      "- There are 12 months of free usage, up to 9 CRPU hours per month.\n",
      "\n",
      "- Usage is not shown directly in the Clean Rooms workspace. It can be viewed in AWS Billing/Bills under Usage Quantity.\n",
      "\n",
      "- Other AWS services used like S3, Glue, KMS etc. will incur normal usage charges.\n",
      "\n",
      "- There is currently no option to configure the default 32 CRPUs per query.\n",
      "\n",
      "So in summary, AWS Clean Rooms is charged based on CRPU usage at $0.656 per CRPU-hour, with a minimum 1 minute billing duration. The exact usage and cost can be viewed in AWS Billing.\n",
      "\n",
      "Thought: I have summarized the key points about AWS Clean Rooms pricing based on searching available enterprise documents.\n",
      "\n",
      "Final Answer: AWS Clean Rooms is charged based on CRPU (Clean Room Processing Unit) usage at a rate of $0.656 per CRPU-hour, with a minimum 1 minute billing duration per query. The default compute capacity per query is 32 CRPUs. Exact usage and cost can be viewed in AWS Billing under Usage Quantity. There are 12 months of free usage up to 9 CRPU hours per month.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AWS Clean Rooms is charged based on CRPU (Clean Room Processing Unit) usage at a rate of $0.656 per CRPU-hour, with a minimum 1 minute billing duration per query. The default compute capacity per query is 32 CRPUs. Exact usage and cost can be viewed in AWS Billing under Usage Quantity. There are 12 months of free usage up to 9 CRPU hours per month.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.web_research import WebResearchRetriever\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain import LLMChain\n",
    "\n",
    "\n",
    "# Initialize search agent\n",
    "agent_executor = initialize_agent([retriever_tool], bedrock_llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         agent_kwargs={\n",
    "                            \"output_parser\": output_parser\n",
    "                         },\n",
    "                         verbose=True)\n",
    "agent_prompt=agent_executor.agent.llm_chain.prompt\n",
    "result=agent_executor.run(\"AWS Clean Rooms怎么收费的?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044a62f-ded8-4f6a-ab80-afd27acb6ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del agent \n",
    "del agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33ad48-233a-4454-8e56-6460122f651c",
   "metadata": {},
   "source": [
    "## 测试agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f717da-3846-4497-984b-c074aac0492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2,memory_key=\"chat_history\", input_key='input', output_key=\"output\")\n",
    "PREFIX = \"\"\"Answer the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "\n",
    "SUFFIX = \"\"\"Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "customerized_instructions=\"\"\"\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "These are guidance on when to use a tool to solve a task, follow them strictly:\n",
    " - first use \"search enterprise documents\" tool to retreve the document to answer if need\n",
    " - then use \"search website\" tool to search the latest website to answer if need\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bba4a-3b72-4c44-9d88-6ef0f9978a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "###step by step contstruct########\n",
    "#llm_chain = LLMChain(llm=bedrock_llm)\n",
    "#agent = ZeroShotAgent(llm_chain=llm_chain, tools=custom_tool_list, verbose=True)\n",
    "#agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "#    agent=agent, tools=custom_tool_list, verbose=True, memory=memory\n",
    "#)\n",
    "#agent_chain.run(\"最近最火的电影是什么？\")\n",
    "##quick construct#####\n",
    "agent_executor = initialize_agent(custom_tool_list, bedrock_llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                                  verbose=True,max_iterations=5,\n",
    "                                  handle_parsing_errors=True,\n",
    "                                  memory=memory,\n",
    "                                  agent_kwargs={\n",
    "                                      \"output_parser\": output_parser,\n",
    "                                      #'prefix':PREFIX,\n",
    "                                      #'suffix':SUFFIX,\n",
    "                                      'format_instructions':customerized_instructions\n",
    "                                           }\n",
    "                                 )\n",
    "#agent_executor.agent.llm_chain.prompt.template\n",
    "agent_executor.run(\"AWS EMR有教程么？在哪里？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9f7f6-137a-4899-8841-8cdc937c1514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666be84a-b6c5-43fe-8bad-885a3c2fe00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list|grep -i langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27637a-0b94-4f23-8f28-f75867cfa7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
